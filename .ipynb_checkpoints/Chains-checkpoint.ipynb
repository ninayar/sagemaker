{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8311e7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain openai   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "858e8377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import re\n",
    "\n",
    "from getpass import getpass\n",
    "from langchain import OpenAI, PromptTemplate\n",
    "from langchain.chains import LLMChain, LLMMathChain, TransformChain, SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "\n",
    "llm = OpenAI(\n",
    "    temperature=0, \n",
    "    openai_api_key=\"<open-api-key>\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e21a348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(chain, query):\n",
    "    with get_openai_callback() as cb:\n",
    "        result = chain.run(query)\n",
    "        print(f'Spent a total of {cb.total_tokens} tokens')\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c68aeea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMMathChain chain...\u001b[0m\n",
      "What is 13 raised to the .3432 power?\u001b[32;1m\u001b[1;3m\n",
      "```python\n",
      "import math\n",
      "print(math.pow(13, 0.3432))\n",
      "```\n",
      "\u001b[0m\n",
      "Answer: \u001b[33;1m\u001b[1;3m2.4116004626599237\n",
      "\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Spent a total of 169 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer: 2.4116004626599237\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_math = LLMMathChain(llm=llm, verbose=True)\n",
    "\n",
    "count_tokens(llm_math, \"What is 13 raised to the .3432 power?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d8fbed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate a math problem into Python code that can be executed in Python 3 REPL. Use the output of running this code to answer the question.\n",
      "\n",
      "Question: ${{Question with math problem.}}\n",
      "```python\n",
      "${{Code that solves the problem and prints the solution}}\n",
      "```\n",
      "```output\n",
      "${{Output of running the code}}\n",
      "```\n",
      "Answer: ${{Answer}}\n",
      "\n",
      "Begin.\n",
      "\n",
      "Question: What is 37593 * 67?\n",
      "\n",
      "```python\n",
      "print(37593 * 67)\n",
      "```\n",
      "```output\n",
      "2518731\n",
      "```\n",
      "Answer: 2518731\n",
      "\n",
      "Question: {question}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(llm_math.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672948b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da351c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def _call(self, inputs: Dict[str, str]) -> Dict[str, str]:\n",
      "        llm_executor = LLMChain(\n",
      "            prompt=self.prompt, llm=self.llm, callback_manager=self.callback_manager\n",
      "        )\n",
      "        self.callback_manager.on_text(inputs[self.input_key], verbose=self.verbose)\n",
      "        t = llm_executor.predict(question=inputs[self.input_key], stop=[\"```output\"])\n",
      "        return self._process_llm_result(t)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(llm_math._call))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "898a9379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_func(inputs: dict) -> dict:\n",
    "    text = inputs[\"text\"]\n",
    "    \n",
    "    # replace multiple new lines and multiple spaces with a single one\n",
    "    text = re.sub(r'(\\r\\n|\\r|\\n){2,}', r'\\n', text)\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "\n",
    "    return {\"output_text\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7efc548",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_extra_spaces_chain = TransformChain(input_variables=[\"text\"], output_variables=[\"output_text\"], transform=transform_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b3de089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A random text with some irregular spacing.\\n Another one here as well.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_extra_spaces_chain.run('A random text  with   some irregular spacing.\\n\\n\\n     Another one   here as well.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1296060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Paraphrase this text:\n",
    "\n",
    "{output_text}\n",
    "\n",
    "In the style of a {style}.\n",
    "\n",
    "Paraphrase: \"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"style\", \"output_text\"], template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7c077fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_paraphrase_chain = LLMChain(llm=llm, prompt=prompt, output_key='final_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66801176",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_chain = SequentialChain(chains=[clean_extra_spaces_chain, style_paraphrase_chain], input_variables=['text', 'style'], output_variables=['final_output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b47e586",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"\n",
    "Chains allow us to combine multiple \n",
    "\n",
    "\n",
    "components together to create a single, coherent application. \n",
    "\n",
    "For example, we can create a chain that takes user input,       format it with a PromptTemplate, \n",
    "\n",
    "and then passes the formatted response to an LLM. We can build more complex chains by combining     multiple chains together, or by \n",
    "\n",
    "\n",
    "combining chains with other components.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cff603a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 163 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nChains let us link up multiple pieces to make one dope app. Like, we can take user input, style it up with a PromptTemplate, then pass it to an LLM. We can get even more creative by combining multiple chains or mixin' chains with other components.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens(sequential_chain, {'text': input_text, 'style': 'a 90s rapper'})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
